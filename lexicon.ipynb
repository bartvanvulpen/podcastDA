{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Lexicon-based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/Bart/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of all paths to the json-files of english episodes given subset number (bart: 0 , juno: 1, joris: 2)\n",
    "\n",
    "def get_paths_for_en_episodes(subset_number):\n",
    "    \"\"\"\n",
    "    Function returns list of all paths to the json-files of english \n",
    "    episodes given subset number (bart: 0 , juno: 1, joris: 2)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    path1 = 'podcast_data_no_audio/podcasts-transcripts/' + str(subset_number)\n",
    "\n",
    "    folders = listdir(path1)\n",
    "\n",
    "    if '.DS_Store' in folders:\n",
    "        folders.remove('.DS_Store')\n",
    "\n",
    "    podcast_episodes_paths = []\n",
    "\n",
    "    for letter_or_number in tqdm(folders):    \n",
    "        path2 = path1 + '/' + letter_or_number\n",
    "\n",
    "\n",
    "        for show_uri in listdir(path2):\n",
    "            path3 = path2 + '/' + show_uri\n",
    "\n",
    "            # select english shows only\n",
    "            show_metadata = metadata_df.loc[metadata_df['show_filename_prefix'] == show_uri]\n",
    "\n",
    "            if len(show_metadata['language'].unique()) > 0:\n",
    "                if 'en' in show_metadata['language'].unique()[0]:\n",
    "                    for episode_uri in listdir(path3):\n",
    "                        path4 = path3 + '/' + episode_uri\n",
    "\n",
    "                        if '.json' in path4:\n",
    "                            podcast_episodes_paths.append(path4)\n",
    "\n",
    "                \n",
    "        \n",
    "    return len(podcast_episodes_paths), podcast_episodes_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK SentiWordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SentiWordNet_sentiment(sentence, binary = True):\n",
    "    \"\"\"\n",
    "    Returns sentiment score for a podcast utterance with tagged tokens \n",
    "    using SentiWordNet\n",
    "    \"\"\"\n",
    "    \n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    \n",
    "    tagged_tokens = nltk.pos_tag(tokens)\n",
    "    \n",
    "    tokens_sentiment_scores = []\n",
    "    for token in tagged_tokens:\n",
    "        tag = ''\n",
    "        lemma = lemmatizer.lemmatize(token[0])\n",
    "        if token[1].startswith('N'):\n",
    "            tag = 'n'\n",
    "        elif token[1].startswith('J'):\n",
    "            tag = 'a'\n",
    "        elif token[1].startswith('V'):\n",
    "            tag = 'v'\n",
    "        elif token[1].startswith('R'):\n",
    "            tag = 'r'\n",
    "        if tag != '':\n",
    "            synonyms = list(swn.senti_synsets(lemma, tag)) \n",
    "            token_sentiment = 0\n",
    "            if len(synonyms) > 0:\n",
    "                for synonym in synonyms:\n",
    "                    token_sentiment += synonym.pos_score() - synonym.neg_score()\n",
    "                tokens_sentiment_scores.append(token_sentiment/len(synonyms))      \n",
    "                \n",
    "       \n",
    "    if binary == False:\n",
    "    \n",
    "        if tokens_sentiment_scores != []:\n",
    "            \n",
    "            sentiment_score = sum(tokens_sentiment_scores)/len(tokens_sentiment_scores) \n",
    "\n",
    "            if sentiment_score >= 0.001:\n",
    "                return 1\n",
    "            elif sentiment_score < -0.001:\n",
    "                return -1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        else:   \n",
    "            return 0\n",
    "        \n",
    "    elif binary == True:\n",
    "        if tokens_sentiment_scores != []:\n",
    "            sentiment_score = sum(tokens_sentiment_scores)/len(tokens_sentiment_scores) \n",
    "\n",
    "            if sentiment_score >= 0:\n",
    "                return 1\n",
    "            elif sentiment_score < 0:\n",
    "                return 0\n",
    "\n",
    "        else:   \n",
    "            return 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just so people can understand what he just sai...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeah, I mean small businesses tough enough. So...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I think Jughead needs to go, you know, it need...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I don't know it was like I hated it when I was...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yeah, so and that is that is also really based...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment_score\n",
       "0  Just so people can understand what he just sai...              1.0\n",
       "1  Yeah, I mean small businesses tough enough. So...              1.0\n",
       "2  I think Jughead needs to go, you know, it need...              0.0\n",
       "3  I don't know it was like I hated it when I was...              1.0\n",
       "4  Yeah, so and that is that is also really based...              0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.read_csv('labeled_datasets/binary/binary_val.csv', sep='\\t')\n",
    "val_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:27<00:00, 46.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.42      0.45       405\n",
      "         1.0       0.75      0.80      0.77       887\n",
      "\n",
      "    accuracy                           0.68      1292\n",
      "   macro avg       0.62      0.61      0.61      1292\n",
      "weighted avg       0.67      0.68      0.67      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "target_labels = val_df['sentiment_score'].values\n",
    "predicted_labels = []\n",
    "for sample in tqdm(val_df['text']):\n",
    "    predicted_sentiment = SentiWordNet_sentiment(sample, binary=True)\n",
    "    predicted_labels.append(predicted_sentiment)\n",
    "\n",
    "predicted_labels = np.array(predicted_labels)  \n",
    "print(classification_report(target_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-binary validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So I'm sure that's probably where he started g...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>living room we get living room was like that a...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you every Every single person who's neve...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yeah. Yeah, right then we will now move on we ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I do I do. That's fucking disgusting dude. You...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment_score\n",
       "0  So I'm sure that's probably where he started g...              0.0\n",
       "1  living room we get living room was like that a...             -1.0\n",
       "2  Thank you every Every single person who's neve...              1.0\n",
       "3  Yeah. Yeah, right then we will now move on we ...              1.0\n",
       "4  I do I do. That's fucking disgusting dude. You...              1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_val_df = pd.read_csv('labeled_datasets/nonbinary/nonbinary_val.csv', sep='\\t')\n",
    "nb_val_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:18<00:00, 71.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.52      0.42      0.47       436\n",
      "         0.0       0.24      0.08      0.12       197\n",
      "         1.0       0.59      0.78      0.67       659\n",
      "\n",
      "    accuracy                           0.55      1292\n",
      "   macro avg       0.45      0.43      0.42      1292\n",
      "weighted avg       0.51      0.55      0.52      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nb_target_labels = list(nb_val_df['sentiment_score'].values)\n",
    "nb_predicted_labels = []\n",
    "for sample in tqdm(nb_val_df['text']):\n",
    "    nb_predicted_sentiment = SentiWordNet_sentiment(sample, binary=False)\n",
    "    nb_predicted_labels.append(nb_predicted_sentiment)\n",
    "\n",
    "print(classification_report(nb_target_labels, nb_predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dialogue_sentiment_SentiWordNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-77c6cf77155c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Utterance number'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdialogue_sentiment_SentiWordNet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdialogue_sentiment_SentiWordNet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dialogue_sentiment_SentiWordNet' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.xlabel('Utterance number')\n",
    "plt.ylabel('Sentiment')\n",
    "plt.plot(range(0, len(dialogue_sentiment_SentiWordNet)), dialogue_sentiment_SentiWordNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VADER Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def VADER_sentiment(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    return score['pos']-score['neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_sentiment_vader = []\n",
    "for sentence in sentences: \n",
    "    sentiment = VADER_sentiment(sentence)\n",
    "    print(sentence, sentiment)\n",
    "    dialogue_sentiment_vader.append(sentiment)\n",
    "    \n",
    "print(sum(dialogue_sentiment_vader)/len(dialogue_sentiment_vader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.xlabel('Utterance number')\n",
    "plt.ylabel('Sentiment')\n",
    "plt.plot(range(0, len(dialogue_sentiment_vader)), dialogue_sentiment_vader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"apple\" < \"banana\")\n",
    "print(\"Unicode of a\", ord(\"a\"))\n",
    "print(\"Unicode of b\", ord(\"b\"))\n",
    "print(\"Unicode of A\", ord(\"A\"))\n",
    "print(\"Unicode of B\", ord(\"B\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SentiWordNet context-based (manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create manual context based sentiwordnet analyzer, usingn phrases as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier with VADER or SentiWordNet-sentiment labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful links to explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/AntoinePassemiers/Lexicon-Based-Sentiment-Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@datamonsters/sentiment-analysis-tools-overview-part-1-positive-and-negative-words-databases-ae35431a470c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (podcastDA)",
   "language": "python",
   "name": "pycharm-9e74e1a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
