{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Lexicon-based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/Bart/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of all paths to the json-files of english episodes given subset number (bart: 0 , juno: 1, joris: 2)\n",
    "\n",
    "def get_paths_for_en_episodes(subset_number):\n",
    "    \"\"\"\n",
    "    Function returns list of all paths to the json-files of english \n",
    "    episodes given subset number (bart: 0 , juno: 1, joris: 2)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    path1 = 'podcast_data_no_audio/podcasts-transcripts/' + str(subset_number)\n",
    "\n",
    "    folders = listdir(path1)\n",
    "\n",
    "    if '.DS_Store' in folders:\n",
    "        folders.remove('.DS_Store')\n",
    "\n",
    "    podcast_episodes_paths = []\n",
    "\n",
    "    for letter_or_number in tqdm(folders):    \n",
    "        path2 = path1 + '/' + letter_or_number\n",
    "\n",
    "\n",
    "        for show_uri in listdir(path2):\n",
    "            path3 = path2 + '/' + show_uri\n",
    "\n",
    "            # select english shows only\n",
    "            show_metadata = metadata_df.loc[metadata_df['show_filename_prefix'] == show_uri]\n",
    "\n",
    "            if len(show_metadata['language'].unique()) > 0:\n",
    "                if 'en' in show_metadata['language'].unique()[0]:\n",
    "                    for episode_uri in listdir(path3):\n",
    "                        path4 = path3 + '/' + episode_uri\n",
    "\n",
    "                        if '.json' in path4:\n",
    "                            podcast_episodes_paths.append(path4)\n",
    "\n",
    "                \n",
    "        \n",
    "    return len(podcast_episodes_paths), podcast_episodes_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK SentiWordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SentiWordNet_sentiment(utterance, binary = True, nb_margin=0.001):\n",
    "    \"\"\"\n",
    "    Returns sentiment score for a podcast utterance with tagged tokens \n",
    "    using SentiWordNet\n",
    "    \"\"\"\n",
    "    \n",
    "    # tokenize utterance\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    tokens = nltk.word_tokenize(utterance)\n",
    "    \n",
    "    # POS tag utterance\n",
    "    tagged_tokens = nltk.pos_tag(tokens)\n",
    "    \n",
    "    # assign sentiment score using SentiWordNet, including synonyms\n",
    "    tokens_sentiment_scores = []\n",
    "    for token in tagged_tokens:\n",
    "        tag = ''\n",
    "        lemma = lemmatizer.lemmatize(token[0])\n",
    "        if token[1].startswith('N'):\n",
    "            tag = 'n'\n",
    "        elif token[1].startswith('J'):\n",
    "            tag = 'a'\n",
    "        elif token[1].startswith('V'):\n",
    "            tag = 'v'\n",
    "        elif token[1].startswith('R'):\n",
    "            tag = 'r'\n",
    "        if tag != '':\n",
    "            # also get sentiments for synonyms\n",
    "            synonyms = list(swn.senti_synsets(lemma, tag)) \n",
    "            token_sentiment = 0\n",
    "            if len(synonyms) > 0:\n",
    "                for synonym in synonyms:\n",
    "                    token_sentiment += synonym.pos_score() - synonym.neg_score()\n",
    "                tokens_sentiment_scores.append(token_sentiment/len(synonyms))      \n",
    "                \n",
    "    # distinguish between binary (positive, negative) and non binary (pos, neutral, negative)\n",
    "    # predict class based onn SentiWordNet sentiment score, using a tunable margin for neutral class\n",
    "    if binary == False:\n",
    "    \n",
    "        if tokens_sentiment_scores != []:\n",
    "            \n",
    "            sentiment_score = sum(tokens_sentiment_scores)/len(tokens_sentiment_scores) \n",
    "\n",
    "            if sentiment_score >= nb_margin:\n",
    "                return 1\n",
    "            elif sentiment_score < -nb_margin:\n",
    "                return -1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        else:   \n",
    "            return 0\n",
    "        \n",
    "    elif binary == True:\n",
    "        if tokens_sentiment_scores != []:\n",
    "            sentiment_score = sum(tokens_sentiment_scores)/len(tokens_sentiment_scores) \n",
    "\n",
    "            if sentiment_score >= 0:\n",
    "                return 1\n",
    "            elif sentiment_score < 0:\n",
    "                return 0\n",
    "\n",
    "        else:   \n",
    "            return 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just so people can understand what he just sai...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeah, I mean small businesses tough enough. So...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I think Jughead needs to go, you know, it need...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I don't know it was like I hated it when I was...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yeah, so and that is that is also really based...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment_score\n",
       "0  Just so people can understand what he just sai...              1.0\n",
       "1  Yeah, I mean small businesses tough enough. So...              1.0\n",
       "2  I think Jughead needs to go, you know, it need...              0.0\n",
       "3  I don't know it was like I hated it when I was...              1.0\n",
       "4  Yeah, so and that is that is also really based...              0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load binary validation dataset\n",
    "val_df = pd.read_csv('labeled_datasets/binary/binary_val.csv', sep='\\t')\n",
    "val_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:47<00:00, 27.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.42      0.45       405\n",
      "         1.0       0.75      0.80      0.77       887\n",
      "\n",
      "    accuracy                           0.68      1292\n",
      "   macro avg       0.62      0.61      0.61      1292\n",
      "weighted avg       0.67      0.68      0.67      1292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate metrics\n",
    "target_labels = val_df['sentiment_score'].values\n",
    "predicted_labels = []\n",
    "for sample in tqdm(val_df['text']):\n",
    "    predicted_sentiment = SentiWordNet_sentiment(sample, binary=True)\n",
    "    predicted_labels.append(predicted_sentiment)\n",
    "\n",
    "predicted_labels = np.array(predicted_labels)  \n",
    "print(classification_report(target_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-binary validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just so people can understand what he just sai...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeah, I mean small businesses tough enough. So...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I think Jughead needs to go, you know, it need...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I don't know it was like I hated it when I was...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yeah, so and that is that is also really based...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment_score\n",
       "0  Just so people can understand what he just sai...              1.0\n",
       "1  Yeah, I mean small businesses tough enough. So...              1.0\n",
       "2  I think Jughead needs to go, you know, it need...             -1.0\n",
       "3  I don't know it was like I hated it when I was...              1.0\n",
       "4  Yeah, so and that is that is also really based...             -1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load non-binary dataset\n",
    "nb_val_df = pd.read_csv('labeled_datasets/nonbinary/nonbinary_val.csv', sep='\\t')\n",
    "nb_val_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:37<00:00, 34.49it/s]\n",
      "  0%|          | 0/1292 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.48      0.42      0.45       405\n",
      "         0.0       0.18      0.01      0.03       206\n",
      "         1.0       0.60      0.81      0.69       681\n",
      "\n",
      "    accuracy                           0.56      1292\n",
      "   macro avg       0.42      0.41      0.39      1292\n",
      "weighted avg       0.49      0.56      0.51      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:27<00:00, 46.64it/s]\n",
      "  0%|          | 5/1292 [00:00<00:34, 37.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.50      0.41      0.45       405\n",
      "         0.0       0.29      0.08      0.12       206\n",
      "         1.0       0.61      0.80      0.69       681\n",
      "\n",
      "    accuracy                           0.56      1292\n",
      "   macro avg       0.46      0.43      0.42      1292\n",
      "weighted avg       0.52      0.56      0.52      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:17<00:00, 75.54it/s]\n",
      "  0%|          | 5/1292 [00:00<00:32, 39.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.50      0.40      0.44       405\n",
      "         0.0       0.26      0.11      0.15       206\n",
      "         1.0       0.61      0.79      0.69       681\n",
      "\n",
      "    accuracy                           0.56      1292\n",
      "   macro avg       0.46      0.43      0.43      1292\n",
      "weighted avg       0.52      0.56      0.53      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:17<00:00, 72.14it/s]\n",
      "  0%|          | 4/1292 [00:00<00:34, 37.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.50      0.39      0.44       405\n",
      "         0.0       0.27      0.14      0.18       206\n",
      "         1.0       0.61      0.79      0.69       681\n",
      "\n",
      "    accuracy                           0.56      1292\n",
      "   macro avg       0.46      0.44      0.44      1292\n",
      "weighted avg       0.52      0.56      0.53      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:17<00:00, 73.14it/s]\n",
      "  0%|          | 5/1292 [00:00<00:32, 39.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.50      0.36      0.42       405\n",
      "         0.0       0.26      0.17      0.20       206\n",
      "         1.0       0.61      0.78      0.68       681\n",
      "\n",
      "    accuracy                           0.55      1292\n",
      "   macro avg       0.46      0.44      0.44      1292\n",
      "weighted avg       0.52      0.55      0.52      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:17<00:00, 74.18it/s]\n",
      "  0%|          | 5/1292 [00:00<00:33, 38.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.50      0.35      0.41       405\n",
      "         0.0       0.25      0.19      0.22       206\n",
      "         1.0       0.61      0.77      0.68       681\n",
      "\n",
      "    accuracy                           0.55      1292\n",
      "   macro avg       0.46      0.44      0.44      1292\n",
      "weighted avg       0.52      0.55      0.52      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:17<00:00, 75.08it/s]\n",
      "  0%|          | 5/1292 [00:00<00:30, 41.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.50      0.35      0.41       405\n",
      "         0.0       0.26      0.22      0.24       206\n",
      "         1.0       0.62      0.76      0.68       681\n",
      "\n",
      "    accuracy                           0.54      1292\n",
      "   macro avg       0.46      0.44      0.44      1292\n",
      "weighted avg       0.52      0.54      0.53      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:17<00:00, 75.45it/s]\n",
      "  0%|          | 5/1292 [00:00<00:33, 38.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.52      0.34      0.41       405\n",
      "         0.0       0.25      0.25      0.25       206\n",
      "         1.0       0.62      0.75      0.68       681\n",
      "\n",
      "    accuracy                           0.54      1292\n",
      "   macro avg       0.46      0.45      0.45      1292\n",
      "weighted avg       0.53      0.54      0.53      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:28<00:00, 45.62it/s]\n",
      "  0%|          | 5/1292 [00:00<00:28, 45.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.52      0.34      0.41       405\n",
      "         0.0       0.24      0.27      0.25       206\n",
      "         1.0       0.62      0.73      0.67       681\n",
      "\n",
      "    accuracy                           0.53      1292\n",
      "   macro avg       0.46      0.45      0.44      1292\n",
      "weighted avg       0.53      0.53      0.52      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:17<00:00, 74.35it/s]\n",
      "  0%|          | 5/1292 [00:00<00:28, 45.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.009000000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.54      0.33      0.41       405\n",
      "         0.0       0.24      0.31      0.27       206\n",
      "         1.0       0.62      0.72      0.67       681\n",
      "\n",
      "    accuracy                           0.53      1292\n",
      "   macro avg       0.47      0.45      0.45      1292\n",
      "weighted avg       0.54      0.53      0.52      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:17<00:00, 72.33it/s]\n",
      "  0%|          | 5/1292 [00:00<00:28, 45.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.54      0.32      0.41       405\n",
      "         0.0       0.23      0.32      0.27       206\n",
      "         1.0       0.62      0.70      0.66       681\n",
      "\n",
      "    accuracy                           0.52      1292\n",
      "   macro avg       0.47      0.45      0.45      1292\n",
      "weighted avg       0.54      0.52      0.52      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:17<00:00, 75.48it/s]\n",
      "  0%|          | 5/1292 [00:00<00:28, 44.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.011\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.55      0.32      0.40       405\n",
      "         0.0       0.24      0.34      0.28       206\n",
      "         1.0       0.63      0.70      0.66       681\n",
      "\n",
      "    accuracy                           0.52      1292\n",
      "   macro avg       0.47      0.45      0.45      1292\n",
      "weighted avg       0.54      0.52      0.52      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:16<00:00, 76.25it/s]\n",
      "  0%|          | 5/1292 [00:00<00:36, 35.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.56      0.31      0.39       405\n",
      "         0.0       0.24      0.38      0.29       206\n",
      "         1.0       0.63      0.68      0.66       681\n",
      "\n",
      "    accuracy                           0.52      1292\n",
      "   macro avg       0.48      0.46      0.45      1292\n",
      "weighted avg       0.54      0.52      0.52      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:34<00:00, 37.14it/s]\n",
      "  0%|          | 4/1292 [00:00<00:39, 32.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.013000000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.55      0.29      0.38       405\n",
      "         0.0       0.24      0.40      0.30       206\n",
      "         1.0       0.64      0.68      0.66       681\n",
      "\n",
      "    accuracy                           0.51      1292\n",
      "   macro avg       0.47      0.46      0.44      1292\n",
      "weighted avg       0.54      0.51      0.51      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:35<00:00, 36.66it/s]\n",
      "  0%|          | 6/1292 [00:00<00:21, 59.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.55      0.28      0.38       405\n",
      "         0.0       0.22      0.40      0.29       206\n",
      "         1.0       0.64      0.67      0.65       681\n",
      "\n",
      "    accuracy                           0.51      1292\n",
      "   macro avg       0.47      0.45      0.44      1292\n",
      "weighted avg       0.55      0.51      0.51      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:17<00:00, 72.54it/s] \n",
      "  0%|          | 5/1292 [00:00<00:37, 34.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.55      0.28      0.37       405\n",
      "         0.0       0.22      0.42      0.29       206\n",
      "         1.0       0.64      0.66      0.65       681\n",
      "\n",
      "    accuracy                           0.50      1292\n",
      "   macro avg       0.47      0.45      0.44      1292\n",
      "weighted avg       0.55      0.50      0.51      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:35<00:00, 36.31it/s]\n",
      "  0%|          | 0/1292 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.55      0.27      0.36       405\n",
      "         0.0       0.22      0.44      0.29       206\n",
      "         1.0       0.64      0.65      0.65       681\n",
      "\n",
      "    accuracy                           0.50      1292\n",
      "   macro avg       0.47      0.45      0.43      1292\n",
      "weighted avg       0.55      0.50      0.50      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:35<00:00, 36.47it/s]\n",
      "  1%|          | 9/1292 [00:00<00:14, 88.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.017\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.55      0.26      0.35       405\n",
      "         0.0       0.22      0.45      0.29       206\n",
      "         1.0       0.65      0.64      0.65       681\n",
      "\n",
      "    accuracy                           0.49      1292\n",
      "   macro avg       0.47      0.45      0.43      1292\n",
      "weighted avg       0.55      0.49      0.50      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:26<00:00, 49.62it/s]\n",
      "  0%|          | 5/1292 [00:00<00:46, 27.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.018000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.55      0.26      0.35       405\n",
      "         0.0       0.22      0.48      0.30       206\n",
      "         1.0       0.65      0.62      0.63       681\n",
      "\n",
      "    accuracy                           0.48      1292\n",
      "   macro avg       0.47      0.45      0.43      1292\n",
      "weighted avg       0.55      0.48      0.49      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:33<00:00, 38.67it/s]\n",
      "  1%|          | 10/1292 [00:00<00:13, 91.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.019\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.55      0.25      0.34       405\n",
      "         0.0       0.22      0.50      0.30       206\n",
      "         1.0       0.65      0.60      0.63       681\n",
      "\n",
      "    accuracy                           0.48      1292\n",
      "   macro avg       0.47      0.45      0.42      1292\n",
      "weighted avg       0.55      0.48      0.49      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:29<00:00, 44.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.54      0.23      0.33       405\n",
      "         0.0       0.21      0.53      0.30       206\n",
      "         1.0       0.66      0.59      0.62       681\n",
      "\n",
      "    accuracy                           0.47      1292\n",
      "   macro avg       0.47      0.45      0.42      1292\n",
      "weighted avg       0.55      0.47      0.48      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate metrics for each parameter value for the non binary margin\n",
    "nb_target_labels = list(nb_val_df['sentiment_score'].values)\n",
    "margin_values = np.linspace(0, 0.02, 21)\n",
    "for margin in margin_values:\n",
    "    nb_predicted_labels = []\n",
    "    for sample in tqdm(nb_val_df['text']):\n",
    "        nb_predicted_sentiment = SentiWordNet_sentiment(sample, binary=False, nb_margin=margin)\n",
    "        nb_predicted_labels.append(nb_predicted_sentiment)\n",
    "    print('Metrics for margin = {}'.format(margin))    \n",
    "    print(classification_report(nb_target_labels, nb_predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VADER Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def VADER_sentiment_classifier(utterance, binary=True, nb_margin=0.001):\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "    score = analyser.polarity_scores(utterance)['compound']\n",
    "    \n",
    "    if binary == False:\n",
    "\n",
    "        if score >= nb_margin:\n",
    "            return 1\n",
    "        elif score < -nb_margin:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    elif binary == True:\n",
    "        \n",
    "        if score >= 0:\n",
    "            return 1\n",
    "        elif score < 0:\n",
    "            return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary VADER validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:33<00:00, 38.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.26      0.38       405\n",
      "         1.0       0.74      0.94      0.83       887\n",
      "\n",
      "    accuracy                           0.73      1292\n",
      "   macro avg       0.71      0.60      0.60      1292\n",
      "weighted avg       0.72      0.73      0.69      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "target_labels = val_df['sentiment_score'].values\n",
    "predicted_labels = []\n",
    "for sample in tqdm(val_df['text']):\n",
    "    predicted_sentiment = VADER_sentiment_classifier(sample, binary=True)\n",
    "    predicted_labels.append(predicted_sentiment)\n",
    "\n",
    "predicted_labels = np.array(predicted_labels)  \n",
    "print(classification_report(target_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-binary VADER validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:31<00:00, 40.44it/s]\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  0%|          | 3/1292 [00:00<00:55, 23.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.38       405\n",
      "         0.0       0.00      0.00      0.00       206\n",
      "         1.0       0.57      0.95      0.71       681\n",
      "\n",
      "    accuracy                           0.58      1292\n",
      "   macro avg       0.42      0.40      0.36      1292\n",
      "weighted avg       0.51      0.58      0.49      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:34<00:00, 42.31it/s]\n",
      "  0%|          | 5/1292 [00:00<00:31, 41.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.38       405\n",
      "         0.0       0.55      0.41      0.47       206\n",
      "         1.0       0.62      0.90      0.74       681\n",
      "\n",
      "    accuracy                           0.62      1292\n",
      "   macro avg       0.62      0.52      0.53      1292\n",
      "weighted avg       0.63      0.62      0.58      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:31<00:00, 40.43it/s]\n",
      "  0%|          | 5/1292 [00:00<00:28, 44.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.38       405\n",
      "         0.0       0.55      0.41      0.47       206\n",
      "         1.0       0.62      0.90      0.74       681\n",
      "\n",
      "    accuracy                           0.62      1292\n",
      "   macro avg       0.62      0.52      0.53      1292\n",
      "weighted avg       0.63      0.62      0.58      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:31<00:00, 44.33it/s]\n",
      "  0%|          | 5/1292 [00:00<00:31, 41.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.38       405\n",
      "         0.0       0.55      0.41      0.47       206\n",
      "         1.0       0.62      0.90      0.74       681\n",
      "\n",
      "    accuracy                           0.62      1292\n",
      "   macro avg       0.62      0.52      0.53      1292\n",
      "weighted avg       0.63      0.62      0.58      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:54<00:00, 39.15it/s]\n",
      "  0%|          | 3/1292 [00:00<00:47, 26.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.38       405\n",
      "         0.0       0.55      0.41      0.47       206\n",
      "         1.0       0.62      0.90      0.74       681\n",
      "\n",
      "    accuracy                           0.62      1292\n",
      "   macro avg       0.62      0.52      0.53      1292\n",
      "weighted avg       0.63      0.62      0.58      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:45<00:00, 25.82it/s]\n",
      "  0%|          | 4/1292 [00:00<00:38, 33.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.38       405\n",
      "         0.0       0.55      0.41      0.47       206\n",
      "         1.0       0.62      0.90      0.74       681\n",
      "\n",
      "    accuracy                           0.62      1292\n",
      "   macro avg       0.62      0.52      0.53      1292\n",
      "weighted avg       0.63      0.62      0.58      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [01:07<00:00, 13.25it/s]\n",
      "  0%|          | 0/1292 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.38       405\n",
      "         0.0       0.55      0.41      0.47       206\n",
      "         1.0       0.62      0.90      0.74       681\n",
      "\n",
      "    accuracy                           0.62      1292\n",
      "   macro avg       0.62      0.52      0.53      1292\n",
      "weighted avg       0.63      0.62      0.58      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [01:27<00:00, 14.81it/s]\n",
      "  0%|          | 3/1292 [00:00<00:58, 22.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.38       405\n",
      "         0.0       0.55      0.41      0.47       206\n",
      "         1.0       0.62      0.90      0.74       681\n",
      "\n",
      "    accuracy                           0.62      1292\n",
      "   macro avg       0.62      0.52      0.53      1292\n",
      "weighted avg       0.63      0.62      0.58      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [01:00<00:00, 30.44it/s]\n",
      "  0%|          | 4/1292 [00:00<00:36, 35.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.38       405\n",
      "         0.0       0.55      0.41      0.47       206\n",
      "         1.0       0.62      0.90      0.74       681\n",
      "\n",
      "    accuracy                           0.62      1292\n",
      "   macro avg       0.62      0.52      0.53      1292\n",
      "weighted avg       0.63      0.62      0.58      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:46<00:00, 27.52it/s]\n",
      "  0%|          | 5/1292 [00:00<00:27, 46.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.009000000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.38       405\n",
      "         0.0       0.55      0.41      0.47       206\n",
      "         1.0       0.62      0.90      0.74       681\n",
      "\n",
      "    accuracy                           0.62      1292\n",
      "   macro avg       0.62      0.52      0.53      1292\n",
      "weighted avg       0.63      0.62      0.58      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:53<00:00, 23.96it/s]\n",
      "  0%|          | 3/1292 [00:00<00:50, 25.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.38       405\n",
      "         0.0       0.55      0.41      0.47       206\n",
      "         1.0       0.62      0.90      0.74       681\n",
      "\n",
      "    accuracy                           0.62      1292\n",
      "   macro avg       0.62      0.52      0.53      1292\n",
      "weighted avg       0.63      0.62      0.58      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:56<00:00, 23.01it/s]\n",
      "  0%|          | 4/1292 [00:00<00:47, 27.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.011\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.38       405\n",
      "         0.0       0.55      0.41      0.47       206\n",
      "         1.0       0.62      0.90      0.74       681\n",
      "\n",
      "    accuracy                           0.62      1292\n",
      "   macro avg       0.62      0.52      0.53      1292\n",
      "weighted avg       0.63      0.62      0.58      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:46<00:00, 27.78it/s]\n",
      "  0%|          | 5/1292 [00:00<00:31, 41.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.38       405\n",
      "         0.0       0.55      0.41      0.47       206\n",
      "         1.0       0.62      0.90      0.74       681\n",
      "\n",
      "    accuracy                           0.62      1292\n",
      "   macro avg       0.62      0.52      0.53      1292\n",
      "weighted avg       0.63      0.62      0.58      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [01:01<00:00, 20.85it/s]\n",
      "  0%|          | 5/1292 [00:00<00:30, 42.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.013000000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.38       405\n",
      "         0.0       0.55      0.41      0.47       206\n",
      "         1.0       0.62      0.90      0.74       681\n",
      "\n",
      "    accuracy                           0.62      1292\n",
      "   macro avg       0.62      0.52      0.53      1292\n",
      "weighted avg       0.63      0.62      0.58      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:37<00:00, 47.72it/s]\n",
      "  0%|          | 5/1292 [00:00<00:27, 47.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.38       405\n",
      "         0.0       0.55      0.41      0.47       206\n",
      "         1.0       0.62      0.90      0.74       681\n",
      "\n",
      "    accuracy                           0.62      1292\n",
      "   macro avg       0.62      0.52      0.53      1292\n",
      "weighted avg       0.63      0.62      0.58      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:33<00:00, 46.68it/s]\n",
      "  0%|          | 5/1292 [00:00<00:27, 46.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.38       405\n",
      "         0.0       0.55      0.41      0.47       206\n",
      "         1.0       0.62      0.90      0.74       681\n",
      "\n",
      "    accuracy                           0.62      1292\n",
      "   macro avg       0.62      0.52      0.53      1292\n",
      "weighted avg       0.63      0.62      0.58      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:38<00:00, 33.28it/s]\n",
      "  0%|          | 2/1292 [00:00<01:27, 14.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.38       405\n",
      "         0.0       0.55      0.41      0.47       206\n",
      "         1.0       0.62      0.90      0.74       681\n",
      "\n",
      "    accuracy                           0.62      1292\n",
      "   macro avg       0.62      0.52      0.53      1292\n",
      "weighted avg       0.63      0.62      0.58      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:54<00:00, 23.60it/s]\n",
      "  0%|          | 1/1292 [00:00<03:13,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.017\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.38       405\n",
      "         0.0       0.55      0.41      0.47       206\n",
      "         1.0       0.62      0.90      0.74       681\n",
      "\n",
      "    accuracy                           0.62      1292\n",
      "   macro avg       0.62      0.52      0.53      1292\n",
      "weighted avg       0.63      0.62      0.58      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:44<00:00, 55.91it/s]\n",
      "  0%|          | 5/1292 [00:00<00:29, 43.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.018000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.38       405\n",
      "         0.0       0.55      0.41      0.47       206\n",
      "         1.0       0.62      0.90      0.74       681\n",
      "\n",
      "    accuracy                           0.62      1292\n",
      "   macro avg       0.62      0.52      0.53      1292\n",
      "weighted avg       0.63      0.62      0.58      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:40<00:00, 28.76it/s]\n",
      "  0%|          | 3/1292 [00:00<00:43, 29.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.019\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.38       405\n",
      "         0.0       0.55      0.41      0.47       206\n",
      "         1.0       0.62      0.90      0.74       681\n",
      "\n",
      "    accuracy                           0.62      1292\n",
      "   macro avg       0.62      0.52      0.53      1292\n",
      "weighted avg       0.63      0.62      0.58      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1292/1292 [00:47<00:00, 19.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for margin = 0.02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.68      0.26      0.37       405\n",
      "         0.0       0.54      0.41      0.47       206\n",
      "         1.0       0.62      0.90      0.74       681\n",
      "\n",
      "    accuracy                           0.62      1292\n",
      "   macro avg       0.62      0.52      0.53      1292\n",
      "weighted avg       0.63      0.62      0.58      1292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate metrics for each parameter value for the non binary margin\n",
    "nb_target_labels = list(nb_val_df['sentiment_score'].values)\n",
    "margin_values = np.linspace(0, 0.02, 21)\n",
    "for margin in margin_values:\n",
    "    nb_predicted_labels = []\n",
    "    for sample in tqdm(nb_val_df['text']):\n",
    "        nb_predicted_sentiment = VADER_sentiment_classifier(sample, binary=False, nb_margin=margin)\n",
    "        nb_predicted_labels.append(nb_predicted_sentiment)\n",
    "    print('Metrics for margin = {}'.format(margin))   \n",
    "    print(classification_report(nb_target_labels, nb_predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (podcastDA)",
   "language": "python",
   "name": "pycharm-9e74e1a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
